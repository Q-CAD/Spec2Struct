{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ase\n",
    "from glob import glob\n",
    "from ase import Atoms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "\n",
    "from atomdiff.models.prior import LitScoreNet\n",
    "from atomdiff.models.forward import LitDOSNet\n",
    "from atomdiff.datasets import *\n",
    "\n",
    "from graphite.nn import periodic_radius_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting PyG Data objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17386/17386 [00:01<00:00, 15449.15it/s]\n",
      "100%|██████████| 17386/17386 [00:01<00:00, 17029.60it/s]\n"
     ]
    }
   ],
   "source": [
    "data_module = StructureDataModule(\n",
    "    data_dir='/net/csefiles/coc-fung-cluster/Shuyi/Datasets/dos/mp_dos_20_train_17386.json',\n",
    "    cutoff=5.0,\n",
    "    train_prior=True,\n",
    "    k=0.8,\n",
    "    train_size=0.9,\n",
    "    scale_y=1.0,\n",
    "    dup=1,\n",
    "    batch_size=8,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "score_net = LitScoreNet.load_from_checkpoint(\n",
    "    './training_logs/mp-dos-20-17386-dup1/version_1/checkpoints/epoch=999-step=544000.ckpt'\n",
    ")\n",
    "\n",
    "data_module.setup()\n",
    "diffuser = data_module.train_set.diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_model = LitDOSNet.load_from_checkpoint(\n",
    "    \"./training_logs/dos_net/version_2/checkpoints/epoch=183-step=200000.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def prior_score(z, pos, cell, t, cutoff=data_module.cutoff):\n",
    "    edge_index, edge_vec = periodic_radius_graph(pos, cutoff, cell)\n",
    "    edge_len  = edge_vec.norm(dim=-1, keepdim=True)\n",
    "    edge_attr = torch.hstack([edge_vec, edge_len])\n",
    "    return score_net.ema_model(z, edge_index, edge_attr, t, diffuser.sigma(t))\n",
    "\n",
    "class LikelihoodScore_Chung(nn.Module):\n",
    "    def __init__(self, score_model, forward_model, y, rho=1.0):\n",
    "        super().__init__()\n",
    "        self.score_model = score_model\n",
    "        self.forward_model = forward_model\n",
    "        self.y = y\n",
    "        self.rho = rho\n",
    "\n",
    "    def forward(self, z, pos, cell, t, cutoff=3.0):\n",
    "        with torch.enable_grad():\n",
    "            # Prepare for autograd\n",
    "            pos.detach()\n",
    "            pos.requires_grad = True\n",
    "\n",
    "            # Convert to graph\n",
    "            edge_index, edge_vec = periodic_radius_graph(pos, cutoff, cell)\n",
    "            edge_attr = torch.hstack([edge_vec, edge_vec.norm(dim=-1, keepdim=True)])\n",
    "\n",
    "            # Estimate clean pos\n",
    "            sigma = diffuser.sigma(t)\n",
    "            score = self.score_model(z, edge_index, edge_attr, t, sigma)\n",
    "            est_clean_pos = pos + sigma.pow(2)*score\n",
    "\n",
    "            # Convert to graph again\n",
    "            edge_index, edge_vec = periodic_radius_graph(pos, cutoff, cell)\n",
    "            edge_attr = torch.hstack([edge_vec, edge_vec.norm(dim=-1, keepdim=True)])\n",
    "\n",
    "            # Compute likelihood score\n",
    "            pred_y = self.forward_model(z, edge_index, edge_attr)\n",
    "            norm = torch.linalg.norm(self.y - pred_y, dim=1, keepdim=True)\n",
    "            grad = torch.autograd.grad([norm.square().mean()], pos)[0]\n",
    "        return - (self.rho / norm) * grad, norm\n",
    "    \n",
    "class ConditionalScore(nn.Module):\n",
    "    def __init__(self, prior_score_fn, likelihood_score_fn):\n",
    "        super().__init__()\n",
    "        self.prior_score_fn = prior_score_fn\n",
    "        self.likelihood_score_fn = likelihood_score_fn\n",
    "    \n",
    "    def forward(self, z, pos, cell, t):\n",
    "        p_score = self.prior_score_fn(z, pos, cell, t)\n",
    "        l_score, norm = self.likelihood_score_fn(z, pos, cell, t)\n",
    "        # print(f'p-score norm: {p_score.norm().item():.3f}, l-score norm: {l_score.norm().item():.3f}, tgt norm: {norm.mean().item():.4f}')\n",
    "        return p_score + l_score\n",
    "\n",
    "# def cond_score(z, pos, cell, t):\n",
    "#     p_score = prior_score(z, pos, cell, t)\n",
    "#     l_score, norm = LikelihoodScore_Chung._forward(z, pos, cell, t)\n",
    "#     print(f'p-score norm: {p_score.norm().item():.3f}, l-score norm: {l_score.norm().item():.3f}, tgt norm: {norm.mean().item():.4f}')\n",
    "#     return p_score + l_score\n",
    "\n",
    "def denoise_by_sde(z, pos, cell, score_fn, ts=torch.linspace(0.999, 0.001, 128+1)):\n",
    "    ts = ts.to(pos.device).view(-1, 1)\n",
    "    pos_traj = [pos.clone()]\n",
    "    f, g, g2 = diffuser.f, diffuser.g, diffuser.g2\n",
    "    for i, t in enumerate(ts[1:]):\n",
    "        dt = ts[i+1] - ts[i]\n",
    "        eps = dt.abs().sqrt() * torch.randn_like(pos)\n",
    "        score = score_fn(z, pos, cell, t)\n",
    "        disp = (f(t)*pos - g2(t)*score)*dt + g(t)*eps\n",
    "        pos += disp\n",
    "        pos_traj.append(pos.clone())\n",
    "    return torch.stack(pos_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "forward_model = forward_model.to(device)\n",
    "score_net = score_net.to(device)\n",
    "\n",
    "val_data_path = \"/net/csefiles/coc-fung-cluster/Shuyi/Datasets/dos/mp_dos_20_val_5910.json\"\n",
    "f = open(val_data_path, 'r')\n",
    "val_data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5910/5910 [1:18:35<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "save_path = \"outputs/conditional_dos_val/\"\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "posteriors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(val_data):\n",
    "        atoms = ase.Atoms(\n",
    "            numbers=data['atomic_numbers'],\n",
    "            positions=data['positions'],\n",
    "            cell=data['cell'],\n",
    "            pbc=[True] * 3\n",
    "        )\n",
    "\n",
    "        sname = data['structure_id']\n",
    "\n",
    "        pos = torch.tensor(atoms.positions, dtype=torch.float, device=device)\n",
    "        cell = torch.tensor(atoms.cell.array, dtype=torch.float, device=device)\n",
    "        atomic_numbers = atoms.numbers\n",
    "\n",
    "        # target\n",
    "        target_y = torch.tensor(data['y'], dtype=torch.float, device=device)\n",
    "        likelihood_score = LikelihoodScore_Chung(\n",
    "            score_model=score_net.ema_model, \n",
    "            forward_model=forward_model.ema_model, \n",
    "            y=target_y, \n",
    "            rho=800.0\n",
    "        )\n",
    "\n",
    "        cond_score = ConditionalScore(prior_score, likelihood_score)\n",
    "\n",
    "        # random positions\n",
    "        random_pos = torch.rand_like(pos, device=device) @ cell\n",
    "        random_pos_clone = random_pos.clone().detach()\n",
    "\n",
    "        # initialize z \n",
    "        z = torch.tensor(atoms.numbers, device=device)\n",
    "        z = data_module.train_set.atom_encoder(z)\n",
    "        z = z.float()\n",
    "        \n",
    "        pos_traj = denoise_by_sde(z, pos, cell, cond_score, ts=torch.linspace(0.999, 0.001, 64+1))\n",
    "\n",
    "        # save traj\n",
    "        denoise_traj = [\n",
    "            ase.Atoms(\n",
    "                numbers=atomic_numbers,\n",
    "                positions=each.detach().cpu().numpy(),\n",
    "                cell=cell.cpu().numpy(),\n",
    "                pbc=[True] * 3\n",
    "            )\n",
    "            for each in pos_traj\n",
    "        ]\n",
    "\n",
    "        ase.io.write(f\"{save_path}{sname}.extxyz\", denoise_traj)\n",
    "\n",
    "\n",
    "        # save final structure\n",
    "        atoms = ase.Atoms(\n",
    "            numbers=atomic_numbers,\n",
    "            positions=pos_traj[-1].detach().cpu().numpy(),\n",
    "            cell=cell.cpu().numpy(),\n",
    "            pbc=[True] * 3\n",
    "        )\n",
    "\n",
    "        ase.io.write(f\"{save_path}{sname}_final.cif\", atoms)\n",
    "\n",
    "        # save_initial_structure\n",
    "        atoms = ase.Atoms(\n",
    "            numbers=atomic_numbers,\n",
    "            positions=random_pos_clone.cpu().numpy(),\n",
    "            cell=cell.cpu().numpy(),\n",
    "            pbc=[True] * 3\n",
    "        )\n",
    "\n",
    "        ase.io.write(f\"{save_path}{sname}_initial.cif\", atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
